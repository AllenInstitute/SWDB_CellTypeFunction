{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "513171da-0760-4543-937b-18a5d97fc99f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "\n",
    "## Space\n",
    "The analysis we did during the workshop did not take into account physical space. If neurons near each other have more similar functional properties, and neurons near to one another are more likely to be connected, this effect might be explained just by spatial factors. How big are those effects? Can they explain this shift?\n",
    "\n",
    "There is good evidence that synapses located close to the cell body of equal size are functionally stronger than synapses which are farther from the cell body.  \n",
    "\n",
    "This exercise is longer and more complex than the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55057c97-1efd-434f-b9ce-7117080c8726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import caveclient\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea417aac-704f-4453-8681-f337bb424878",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### We will start with recalculating the dataframe from the workshop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "693ea006-bd2e-467d-878d-68b3c90ff91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import os\n",
    "\n",
    "platstring = platform.platform()\n",
    "if ('Darwin' in platstring) or ('macOS' in platstring):\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2023/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on Code Ocean\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2023/\"\n",
    "    \n",
    "data_dir = os.path.join(data_root, 'microns_in_silico')\n",
    "\n",
    "# you can just override this if the location of the data varies\n",
    "# data_dir = '/Users/forrestc/Downloads/microns_in_silico/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8f7074c-2d59-45e0-9b82-72b28d101f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we are going to load up the data and prepare the dataframe like we did \n",
    "# in class but with fewer comments\n",
    "\n",
    "# load up the in-silico responses as a pandas dataframe from a numpy array \n",
    "resp=pd.DataFrame(np.load(os.path.join(data_dir, 'nat_resp.npy')))\n",
    "\n",
    "# load up the csv of metadata about the 104171 units\n",
    "units_df = pd.read_csv(os.path.join(data_dir, 'nat_unit.csv'))\n",
    "\n",
    "# set the index to the be the row_idx of the units_df\n",
    "resp.index = units_df['row_idx']\n",
    "\n",
    "# if we are on code ocean, the CAVEsetup helped you make your token an environment variable\n",
    "if 'amzn' in platstring:\n",
    "    client= caveclient.CAVEclient('minnie65_public', auth_token=os.environ['API_SECRET'])\n",
    "else:\n",
    "    # otherwise if you are local, then it should be saved to a file in your harddrive \n",
    "    # that the caveclient knows where to read.\n",
    "    client= caveclient.CAVEclient('minnie65_public')\n",
    "\n",
    "# lets pull out the manual coregistered neurons\n",
    "# desired_resolution describes how many nanometers you want each unit to be\n",
    "# so 1000,1000,1000 gives positions in microns for x,y and z\n",
    "coreg_df = client.materialize.query_table('coregistration_manual_v3', desired_resolution=[1000,1000,1000])\n",
    "\n",
    "# lets merge these dataframes so we get the row_idx of each coregistered unit\n",
    "# we merge on the corresponding columns, however scan was called something\n",
    "# slightly different in one csv vs the CAVE table\n",
    "coreg_in_silico=pd.merge(units_df, coreg_df, \n",
    "         left_on=['scan_session', 'scan_idx', 'unit_id'],\n",
    "          right_on=['session','scan_idx', 'unit_id'])\n",
    "# reset the index to make sure that we have the index\n",
    "coreg_in_silico.reset_index(inplace=True)\n",
    "\n",
    "# this will pull out the responses to the coregistered units\n",
    "# by using the row_idx that was provided in the metadata\n",
    "coreg_resp = resp.loc[coreg_in_silico.row_idx,:]\n",
    "\n",
    "# now with a reduced set of units, we can calculate the Pearson correlation\n",
    "# between their responses\n",
    "corr_M = np.corrcoef(coreg_resp.values)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd2f205-4d1c-4f1f-874a-f8aa427984d5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "However this time lets make a dataframe that contains all the correlations\n",
    "but also the nucleus IDs of both sides of the correlation\n",
    "and then merge in the nucleus positions so we can measure the\n",
    "soma to soma distance of that correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "634a8f14-0b52-45d6-ae52-981a85271de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get an array of the nucleus IDs of each row/column of the corr_M\n",
    "\n",
    "\n",
    "# get the row and column indices of the upper right triangle\n",
    "# of this matrix\n",
    "\n",
    "# use the row and column indices to get an array of nucleus IDs on each side of the correlation\n",
    "\n",
    "\n",
    "# use fancy indexing to pull out the correlation values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "beb97013-04d4-4be0-b8e6-ad4cdd5c169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a dataframe using these 3 columns\n",
    "# hint use a a dictionary to name the columns\n",
    "# and include \"copy=False\" to avoid blowing up memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66c3b790-23c2-46fc-84d2-dd2a4f8c9f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the nucleus positions dataframe\n",
    "# converting the positions to microns\n",
    "# and using standard transform to adjust them to be flat\n",
    "nuc_df = client.materialize.query_view('nucleus_detection_lookup_v1', \n",
    "                                        select_columns = ['id', 'pt_root_id', 'pt_position'],\n",
    "                                        desired_resolution=[1,1,1])\n",
    "from standard_transform.datasets import minnie_transform_nm\n",
    "tform=minnie_transform_nm()\n",
    "nuc_df['pt_position']=tform.apply(nuc_df.pt_position)\n",
    "nuc_df['pt_position']=nuc_df.pt_position.apply(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3daefaff-24ef-4dee-a18a-06de984ac1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge on the pre and post positions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "784a2a2f-3fca-4b0f-9371-7dee8572e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first few rows of your dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7ce8386-bf64-4b23-84be-fdc667911179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# measure the distance between the soma of nuc1 and nuc2\n",
    "\n",
    "# measure the distance also in x,z only.. this is along the surface of cortex\n",
    "\n",
    "# hints: look at np.vstack, np.linalg.norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe35f3-d16a-4fd0-bab5-e5cdf656647c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b48e731-8b34-4ace-9bb1-47c9cc63e7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out distances of <2 microns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb6ab0c5-271a-4202-b8c0-8592f466e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using binned statistic, lets measure the avg C as a function of euclidean distance\n",
    "\n",
    "# make up some distance bins from 2-250 microns\n",
    "\n",
    "\n",
    "# use scipy.stats.binned_statistic\n",
    "# to measure correlation as a function of distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f08a1f06-5d8f-4933-9864-fcfe4098bf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfc797ce-eafd-43a2-9d35-f335aec98698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about using the cortical distance\n",
    "# use the same bins\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acec3b14-de00-4688-a818-069e8681cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot of mean Correlation and std error bars a function of distance\n",
    "# put both distances on same plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1831962b-68e4-4211-a4d7-60cda36adfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a plot of how many pairs fall in each of these distance bins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b023a2f-8c99-4b59-b524-28ecffae2b4b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "#### Thought question\n",
    "\n",
    "What explains these curves? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb3eb3a3-45ba-4285-ab11-baf5224cffaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the same plot but for connected pairs of neurons\n",
    "# first lets reconstruct the dataframe from the workshop\n",
    "# we need this code to work in solutions directory\n",
    "# and one up..\n",
    "if 'solutions' in os.getcwd():\n",
    "    workshop2file = '../../workshop2/all_prf_coreg_conn_v661.pkl'\n",
    "else:\n",
    "    workshop2file = '../workshop2/all_prf_coreg_conn_v661.pkl'\n",
    "all_syn_df = pd.read_pickle(workshop2file)\n",
    "\n",
    "# lets merge on the pre and post-synaptic positions of these connections\n",
    "\n",
    "# renaming the positions as pre and post depending on how we did the merge\n",
    "# and drop the duplicate id columns\n",
    "all_syn_dfm=all_syn_df.merge(nuc_df[['id', 'pt_position']], left_on='pre_nuc_id', right_on='id')\\\n",
    ".rename({'pt_position':'pre_pt_position'}, axis=1)\\\n",
    ".merge(nuc_df[['id', 'pt_position']], left_on='post_nuc_id', right_on='id')\\\n",
    ".rename({'pt_position':'post_pt_position'}, axis=1)\\\n",
    ".drop(['id_x', 'id_y'], axis=1)\n",
    "\n",
    "# now lets merge in the neurons that are coregistered with responses\n",
    "\n",
    "# we have to drop duplicates to avoid the few cells that were coregistered twice \n",
    "# being double counted\n",
    "all_syn_dfm2=all_syn_dfm.merge(coreg_in_silico[['index','target_id', 'scan_session', 'scan_idx', 'field','unit_id', 'score', 'residual']],\n",
    "                  left_on='pre_nuc_id', \n",
    "                  right_on='target_id')\\\n",
    ".merge(coreg_in_silico[['index','target_id', 'scan_session', 'scan_idx', 'field','unit_id','score', 'residual']],\n",
    "                  left_on='post_nuc_id', \n",
    "                  right_on='target_id',\n",
    "                  suffixes=['_pre', '_post'])\\\n",
    ".drop(['target_id_pre', 'target_id_post'],axis=1)\\\n",
    ".drop_duplicates(subset=['pre_nuc_id', 'post_nuc_id'])\n",
    "all_syn_dfm2\n",
    "\n",
    "# now use fancy indexing to pull out the correlation associated with each of these connections\n",
    "all_syn_dfm2['C']=corr_M[all_syn_dfm2.index_pre, all_syn_dfm2.index_post]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66e102d7-56e0-4461-aa86-32953a4778f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets cut the dataframe down to just the columns we need\n",
    "df_conn=all_syn_dfm2[['pre_nuc_id', 'post_nuc_id', 'n_syn', 'sum_size', 'C', 'pre_pt_position', 'post_pt_position']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec39ee1a-c83a-4abc-97d9-11bcabfe408f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_nuc_id</th>\n",
       "      <th>post_nuc_id</th>\n",
       "      <th>n_syn</th>\n",
       "      <th>sum_size</th>\n",
       "      <th>C</th>\n",
       "      <th>pre_pt_position</th>\n",
       "      <th>post_pt_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>265045</td>\n",
       "      <td>303145</td>\n",
       "      <td>1</td>\n",
       "      <td>1732</td>\n",
       "      <td>0.169119</td>\n",
       "      <td>[643.0300065048364, 427.88641564546697, 884.36...</td>\n",
       "      <td>[667.8080332150954, 489.8015688177371, 890.640...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>299091</td>\n",
       "      <td>303145</td>\n",
       "      <td>1</td>\n",
       "      <td>7604</td>\n",
       "      <td>0.010837</td>\n",
       "      <td>[709.1922761459178, 345.01749614037846, 895.20...</td>\n",
       "      <td>[667.8080332150954, 489.8015688177371, 890.640...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>292685</td>\n",
       "      <td>303145</td>\n",
       "      <td>1</td>\n",
       "      <td>23668</td>\n",
       "      <td>0.192392</td>\n",
       "      <td>[728.1902267066858, 144.7592334831523, 840.840...</td>\n",
       "      <td>[667.8080332150954, 489.8015688177371, 890.640...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>256576</td>\n",
       "      <td>303145</td>\n",
       "      <td>1</td>\n",
       "      <td>9404</td>\n",
       "      <td>0.040026</td>\n",
       "      <td>[618.4397512164188, 125.9061074383746, 881.280...</td>\n",
       "      <td>[667.8080332150954, 489.8015688177371, 890.640...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>222998</td>\n",
       "      <td>303145</td>\n",
       "      <td>2</td>\n",
       "      <td>25900</td>\n",
       "      <td>0.145264</td>\n",
       "      <td>[600.9084008376958, 131.6961825586517, 919.880...</td>\n",
       "      <td>[667.8080332150954, 489.8015688177371, 890.640...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pre_nuc_id  post_nuc_id  n_syn  sum_size         C  \\\n",
       "0      265045       303145      1      1732  0.169119   \n",
       "1      299091       303145      1      7604  0.010837   \n",
       "2      292685       303145      1     23668  0.192392   \n",
       "4      256576       303145      1      9404  0.040026   \n",
       "5      222998       303145      2     25900  0.145264   \n",
       "\n",
       "                                     pre_pt_position  \\\n",
       "0  [643.0300065048364, 427.88641564546697, 884.36...   \n",
       "1  [709.1922761459178, 345.01749614037846, 895.20...   \n",
       "2  [728.1902267066858, 144.7592334831523, 840.840...   \n",
       "4  [618.4397512164188, 125.9061074383746, 881.280...   \n",
       "5  [600.9084008376958, 131.6961825586517, 919.880...   \n",
       "\n",
       "                                    post_pt_position  \n",
       "0  [667.8080332150954, 489.8015688177371, 890.640...  \n",
       "1  [667.8080332150954, 489.8015688177371, 890.640...  \n",
       "2  [667.8080332150954, 489.8015688177371, 890.640...  \n",
       "4  [667.8080332150954, 489.8015688177371, 890.640...  \n",
       "5  [667.8080332150954, 489.8015688177371, 890.640...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_conn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12fb70b9-6586-442d-a20a-b5f3f48aae33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the intersoma distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1a8706a2-c302-44e2-b63d-c48b1b063823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out the soma distances of <2 microns\n",
    "# to discount the double roi cells\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0211be69-34ad-43ac-ac61-63f4ca19534a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use scipy.stats.binned_statistic\n",
    "# to measure correlation as a function of distance for connected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b21f82-8fd9-4a32-bdeb-5a4b5b0ab37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot both curves for connected and all paris on top of one another\n",
    "# make a plot of mean Correlation and std error bars a function of distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "804393dd-3612-426b-bf23-8de0aee02781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot both curves for connected and all paris on top of one another\n",
    "# make a plot of mean Correlation and std error bars a function of distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51498fe7-c813-4a94-a931-eb67eb9e812c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot how many connected pairs are in each distance bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "054e7ad7-d718-4b26-b637-cd131d71883f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot how many are connected in a cortical distance bin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59b91e-b411-4ba7-89f7-a86a977f963f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "#### Thought questions\n",
    "\n",
    "What explains the difference between this curve and the overall distribution of pairs of recorded ROIs? \n",
    "\n",
    "Does this curve match your expectation for what cortical connectivity should look like?\n",
    "\n",
    "If space explains a lot of the differences between connected and unconnected pairs,\n",
    "what does that mean?\n",
    "\n",
    "How does it affect your interpretation of the effects?\n",
    "\n",
    "Are there spatial effects that go beyond just soma to soma distance that would be important to control for in order to interpret a finding as being evidence for a particular mechanism?\n",
    "\n",
    "#### Extensions/Project Ideas\n",
    "\n",
    "Can you make a model which resamples the all pairs to match the spatial distributions found in the connected dataset?  Are the results significant compared to that null model?\n",
    "\n",
    "Does this explain the variation seen in the single cell effects.. that some cells have closer and farther away targets in the brain?\n",
    "\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
