{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "943a9933-414a-4ec3-931d-a7a289864c14",
   "metadata": {},
   "source": [
    "# Extracting Features from Skeletons\n",
    "\n",
    "The feature extraction pipeline that generated the dataframe we're working with extracts a number of features from each skeleton.\n",
    "This notebook will cover some of these features and introduce you to a design pattern for working with your own ideas for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc96db93-f4da-4192-8e3a-529f8e59de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from meshparty import meshwork\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39a5478a-96a5-451f-8c2d-8e2b2565387b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load an example cell from the data we already have\n",
    "\n",
    "filename = 'data/exampleNets/864691136452201983.h5'\n",
    "nrn = meshwork.load_meshwork(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e23210-b4d4-4cd8-afb4-69a97e2bb121",
   "metadata": {},
   "source": [
    "## Splitting the problem into pieces\n",
    "\n",
    "Let's imagine a couple of features. Rather than make one giant function that does all the features we can imagine, let's take an approach where each feature is one function. This will make things more modular and, we will see, make life more simple in the future.\n",
    "\n",
    "The first feature is the total path length. This one is fairly simple, because there's already a function to compute the path length of the cell. However, we do have to do some work — for example, this is going to just be a dendritic feature, so we need to mask out the axon while doing these computations. We want a function that takes a meshwork object as its input and returns the path length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d189a6-c4ab-4985-a54d-ead2ff3d77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def path_length_dendrite(nrn):\n",
    "    # The mask_context function sets the mask and then resets it after the code inside is run.\n",
    "    with nrn.mask_context(\n",
    "        ~nrn.anno['is_axon'].mesh_mask  # the ~ is a logical not, so this is taking everything that is *not*\n",
    "    ) as nmc:\n",
    "        return nmc.path_length() / 1_000 # Convert to microns from nanometers by dividing by 10^3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2256d9af-dc8e-490b-a7f5-099723e5597d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3117.29"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_length_dendrite(nrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24140c85-3be9-4995-b227-fb6e03ac32d7",
   "metadata": {},
   "source": [
    "Now let's do something with synapses. For example, let's compute the total number and median size of input synapses on the dendrite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cad5597-3254-412a-b61d-546a397f4652",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_synapse_count(nrn):\n",
    "    return len(\n",
    "        nrn.anno.post_syn.filter_query(\n",
    "             ~nrn.anno['is_axon'].mesh_mask\n",
    "        ).df\n",
    "    )\n",
    "    \n",
    "def input_synapse_median_size(nrn):\n",
    "    size_values = nrn.anno.post_syn.filter_query(\n",
    "        ~nrn.anno['is_axon'].mesh_mask\n",
    "    ).df['size'].values\n",
    "    return np.median(size_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6ea6c3a-a4eb-44af-ad79-54f8a4b22837",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_synapse_count(nrn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cfc44d7-7d45-4e66-8d09-7a3bbb4481c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4188.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_synapse_median_size(nrn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083eccb7-faf6-4a47-859b-1f953d744d86",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "How about just getting the number of somatic synapses?\n",
    "\n",
    "*Reminder: To get a mask that is for the soma alone, you can use* `nrn.root_region.to_mesh_mask`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d264392-154a-4acc-bd2f-22cfcac5632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def soma_synapse_count(nrn):\n",
    "    pass\n",
    "    \n",
    "def soma_synapse_median_size(nrn):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86661694-eab1-403b-9eb0-efc27e4fb2a9",
   "metadata": {},
   "source": [
    "### Array output instead of values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec308b9-2b59-4b83-946b-1e1e2204eddc",
   "metadata": {},
   "source": [
    "Now let's add one final nuance, and rather than return a value we'll return an array. The idea here is that we can do some computation based on this array later using information that comes from all the cells collectively — for example, PCA components of some binned property.\n",
    "\n",
    "Let's start by making a function that counts how many synapses of a cell is in each of a depth bin, using the same bins for all cells. In this case, we will split each bin into 20 microns starting at the pia surface, using `standard_transform` to rotate, scale, and translate the synapse coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05c1a0a-c6bb-4003-929d-344ef88b8b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from standard_transform import minnie_ds\n",
    "\n",
    "bins = np.linspace(0,900,46)\n",
    "\n",
    "def synapse_depth_binned(nrn):\n",
    "    # This uses standard transform to get the depth projection of the synapse location.\n",
    "    with nrn.mask_context(~nrn.anno['is_axon'].mesh_mask) as nmc:\n",
    "        counts, _bins = np.histogram(\n",
    "            minnie_ds.transform_vx.apply_dataframe(\n",
    "                    'ctr_pt_position',\n",
    "                    nmc.anno.post_syn.df,\n",
    "                    projection='y',\n",
    "                ),\n",
    "            bins=bins,\n",
    "        )\n",
    "        return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1a6484-6ea4-4259-89b8-e9682aef8001",
   "metadata": {},
   "source": [
    "## Assembling the features together\n",
    "\n",
    "Now let's assemble all of these functions into one collection in order to generate a collection of features (including the two examples you might have written):\n",
    "\n",
    "The gist is that we're going to make a function that takes in a meshwork object (`nrn`) and returns a dictionary where each key is a feature name and each value is the feature value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50f6451f-4b5f-470f-8a7a-b092a6a6fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(nrn):\n",
    "    return {\n",
    "        'path_length': path_length_dendrite(nrn),\n",
    "        'input_syn_count': input_synapse_count(nrn),\n",
    "        'input_syn_median_size': input_synapse_median_size(nrn),\n",
    "        # 'soma_syn_count': soma_synapse_count(nrn),\n",
    "        # 'soma_syn_median_size': soma_synapse_median_size(nrn),   # Uncomment these two lines if you put in a solution to the functions above\n",
    "        'synapse_depth_binned': synapse_depth_binned(nrn),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d280790d-153d-4745-9ea4-e77721138412",
   "metadata": {},
   "source": [
    "The nice thing about this is that it's very modular. If you want to add a feature, write a function and add a line here. Remove a feature? Delete a line. Edit a feature? Change that one function. Easy to read and easy to edit or debug.\n",
    "\n",
    "Moreover, the arrangement as a dict makes it easy to run across several neurons and put into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5cf19574-0f16-4296-bbcd-32c9181a070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are just the root ids with skeletons already in the example data folder\n",
    "root_ids = [864691134965653279, 864691135208968313, 864691135759684174, 864691135866737541, 864691136452201983, 864691136953057759]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd8bd83b-d39f-4c17-9515-5a88ed689e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = []\n",
    "for root_id in root_ids:\n",
    "    filename = f'data/exampleNets/{root_id}.h5'\n",
    "    nrn = meshwork.load_meshwork(filename)\n",
    "    feats.append(\n",
    "        get_features(nrn)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01493f6e-f29a-4549-bea5-0056d0dda453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_length</th>\n",
       "      <th>input_syn_count</th>\n",
       "      <th>input_syn_median_size</th>\n",
       "      <th>synapse_depth_binned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>864691134965653279</th>\n",
       "      <td>2153.34750</td>\n",
       "      <td>1011</td>\n",
       "      <td>5016.0</td>\n",
       "      <td>[8, 48, 31, 19, 18, 22, 6, 2, 10, 16, 41, 240,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864691135208968313</th>\n",
       "      <td>5420.38800</td>\n",
       "      <td>5677</td>\n",
       "      <td>4684.0</td>\n",
       "      <td>[196, 629, 556, 1092, 940, 932, 783, 409, 109,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864691135759684174</th>\n",
       "      <td>2572.20175</td>\n",
       "      <td>1574</td>\n",
       "      <td>4714.0</td>\n",
       "      <td>[0, 3, 14, 9, 11, 8, 6, 11, 10, 12, 10, 11, 16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864691135866737541</th>\n",
       "      <td>7450.01100</td>\n",
       "      <td>10017</td>\n",
       "      <td>4580.0</td>\n",
       "      <td>[89, 219, 234, 157, 162, 90, 97, 51, 60, 111, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864691136452201983</th>\n",
       "      <td>3117.29000</td>\n",
       "      <td>4333</td>\n",
       "      <td>4188.0</td>\n",
       "      <td>[0, 0, 0, 0, 17, 14, 19, 20, 24, 28, 38, 36, 8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864691136953057759</th>\n",
       "      <td>5395.45650</td>\n",
       "      <td>6342</td>\n",
       "      <td>4540.0</td>\n",
       "      <td>[13, 239, 286, 278, 216, 168, 310, 673, 557, 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path_length  input_syn_count  input_syn_median_size  \\\n",
       "864691134965653279   2153.34750             1011                 5016.0   \n",
       "864691135208968313   5420.38800             5677                 4684.0   \n",
       "864691135759684174   2572.20175             1574                 4714.0   \n",
       "864691135866737541   7450.01100            10017                 4580.0   \n",
       "864691136452201983   3117.29000             4333                 4188.0   \n",
       "864691136953057759   5395.45650             6342                 4540.0   \n",
       "\n",
       "                                                 synapse_depth_binned  \n",
       "864691134965653279  [8, 48, 31, 19, 18, 22, 6, 2, 10, 16, 41, 240,...  \n",
       "864691135208968313  [196, 629, 556, 1092, 940, 932, 783, 409, 109,...  \n",
       "864691135759684174  [0, 3, 14, 9, 11, 8, 6, 11, 10, 12, 10, 11, 16...  \n",
       "864691135866737541  [89, 219, 234, 157, 162, 90, 97, 51, 60, 111, ...  \n",
       "864691136452201983  [0, 0, 0, 0, 17, 14, 19, 20, 24, 28, 38, 36, 8...  \n",
       "864691136953057759  [13, 239, 286, 278, 216, 168, 310, 673, 557, 8...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df = pd.DataFrame(\n",
    "    feats,\n",
    "    index=root_ids,\n",
    ")\n",
    "\n",
    "feature_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53ab671-b49b-4c52-8e81-41dc4b48ad2d",
   "metadata": {},
   "source": [
    "## A few extra notes:\n",
    "\n",
    "You can see the functions used in the `skel_features` directory. They are a bit more complicated than what we did here, but only to make them a bit more generic. For example, in order to use potentially different compartments other than just axon/dendrite. In addition, because this was run on many more cells while proofreading was going on, it made sense to be able to store the results of feature extraction as a file (in this case a JSON file), so that if a cell had already had features extracted the values could be looked up instead of re-computed.\n",
    "\n",
    "These were intended as very simple features, and there's a lot more to discover or measure if you want! Be creative!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
